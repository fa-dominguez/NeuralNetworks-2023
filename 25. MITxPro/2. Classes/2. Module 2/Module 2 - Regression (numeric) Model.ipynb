{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcf3f19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math, random\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "432f1452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input [1, 2] => output 3\n"
     ]
    }
   ],
   "source": [
    "# Implement and train a single neuron regression model\n",
    "\n",
    "# ---- Step 1: define the model ----\n",
    "\n",
    "# Define single neuron function\n",
    "def single_neuron_regression_model(w, w_0, x):\n",
    "    '''\n",
    "    Creation of a single neuron regression model. This function calculates the 'z' output vector\n",
    "    and returns the result of the activation function (a) over this vector. w and x must be same length\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    variable  | type  | \n",
    "    w           var.\n",
    "    w_0         float\n",
    "    x           var.\n",
    "    '''\n",
    "    \n",
    "    # Perform the dot product on the input x and the learned weights w (z output vector)\n",
    "    z = 0\n",
    "    \n",
    "    # loop over each feature and weight in x and w vector\n",
    "    # zip function generates a tuple for each x,w pair.\n",
    "    for feature, weight in zip(x, w):\n",
    "        \n",
    "        # z is the sum of all feature * weight\n",
    "        z += feature * weight\n",
    "    \n",
    "    #Add the bias term\n",
    "    z += w_0  \n",
    "    \n",
    "    # Apply the activation function, and return\n",
    "    a = linear(z)\n",
    "    return a\n",
    "\n",
    "# simple linear activiation function: just returns identity\n",
    "def linear(z):\n",
    "    return z\n",
    "\n",
    "\n",
    "# Test model output for a single 2D datapoint:\n",
    "x = [1, 2]\n",
    "w = [5, 3]\n",
    "w_0 = -8\n",
    "\n",
    "# predict y_value\n",
    "# y follows the function: x_1 * w_1 + x_2 * w_2 + w_0\n",
    "y = single_neuron_regression_model(w, w_0, x) \n",
    "\n",
    "# print result\n",
    "print(\"input\", x, \"=> output\", y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4ee7d180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Step 2: train the model ----\n",
    "\n",
    "# define train model based on square error loss function\n",
    "def train_model_SE_loss(m_function, w, w_0, i_data, o_data, learning_rate, num_epochs):\n",
    "    \n",
    "    # Iterates over the number of iterations declared (num_epochs)\n",
    "    for epoch in range(num_epochs):\n",
    "        # Keep track of total loss across the data set \n",
    "        total_loss = 0\n",
    "        # iterates over each pair x,y from input & output data\n",
    "        for x, y in zip(i_data, o_data):\n",
    "            \n",
    "\n",
    "            # calculate predicted y value based on the model function\n",
    "            y_predicted = m_function(w, w_0, x)\n",
    "\n",
    "            # calculate error\n",
    "            error = y_predicted - y\n",
    "            \n",
    "            # sum up the total 'square error' loss of all x, y pairs\n",
    "            total_loss += (error ** 2) / 2\n",
    "            \n",
    "            # Update bias coefficient (w_0) using the gradient\n",
    "            # For bias coefficient dy_predicted/dw_0 is 1.\n",
    "            w_0 -= learning_rate * error * 1\n",
    "            \n",
    "            # Update the rest of the coefficients\n",
    "            # j: keeps index; x_j: keeps coefficient value\n",
    "            for j, x_j in enumerate(x):\n",
    "                \n",
    "                # The derivate dy_predicted / dw_j is x_j\n",
    "                w[j] -= learning_rate * error * x_j\n",
    "                \n",
    "        report_every = max(1, num_epochs // 10)\n",
    "        if epoch % report_every == 0:\n",
    "            print(\"epoch\", epoch, \"has total loss\", total_loss)\n",
    "    return w, w_0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6d132fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Step 3: Evaluate the accuracy of the model\n",
    "def evaluate_regression_accuracy(model_function, w, w_0, i_data, o_data):\n",
    "    total_loss = 0\n",
    "    n = len(i_data)\n",
    "    \n",
    "    for x,y in zip(i_data, o_data):\n",
    "        \n",
    "        # predict the y value based on w, w_0, and x\n",
    "        y_predicted = model_function(w, w_0, x)\n",
    "        \n",
    "        # Calculate the error per iteration\n",
    "        error = y_predicted - y\n",
    "        \n",
    "        # Calculate the square error\n",
    "        total_loss += (error ** 2) /2\n",
    "    \n",
    "    # accuracy calculated as the total loss over the number of features\n",
    "    accuracy = total_loss / n\n",
    "    print(\"Our model has mean square error of\", accuracy)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "78ab4313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ----- Step 4: Plotting the dataset\n",
    "\n",
    "# Declare a one dimension data set\n",
    "X_1D = [[1], [-2], [3], [4.5], [0], [-4], [-1], [4], [-1]]\n",
    "Y_1D = [4,   3,    6,   8,     2,   -3,   -2,   7,   2.5]\n",
    "\n",
    "# Scatter plot of x, y\n",
    "def plot_dataset_1D(x, y):\n",
    "    x_np = np.array(x)\n",
    "    y_np = np.array(y)\n",
    "    # np.array[..., 0] -> Get the first element of each sub element\n",
    "    plt.scatter(x_np[...,0], y_np)\n",
    "\n",
    "def plot_fit_1D(X, w, w_0):\n",
    "    ylim = plt.ylim()\n",
    "    x_np = np.array(X)\n",
    "    y_pred = np.array([single_neuron_regression_model(w, w_0, x) for x in X])\n",
    "    \n",
    "    plt.plot(x_np[..., 0], y_pred, color = 'red')\n",
    "\n",
    "plot_dataset_1D(X_1D, Y_1D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dbbc52a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 has total loss 75.15118164194563\n",
      "epoch 1 has total loss 40.109157956509094\n",
      "epoch 2 has total loss 29.801523004849642\n",
      "epoch 3 has total loss 25.47970121810249\n",
      "epoch 4 has total loss 22.84563043777799\n",
      "epoch 5 has total loss 20.86922066083035\n",
      "epoch 6 has total loss 19.269845776759738\n",
      "epoch 7 has total loss 17.945486824052068\n",
      "epoch 8 has total loss 16.841512143299816\n",
      "epoch 9 has total loss 15.91945696552539\n",
      "epoch 10 has total loss 15.148892782711584\n",
      "Final weights:\n",
      "[1.2616634248232683] 1.589875809042491\n"
     ]
    }
   ],
   "source": [
    "# ----- Step 5: Train the model and call the functions\n",
    "# Let's start with a value of w_0 and w 0\n",
    "w_0 = 0\n",
    "w = [0]\n",
    "learning_rate = 0.01\n",
    "epochs = 11\n",
    "\n",
    "w, w_0 = train_model_SE_loss(single_neuron_regression_model, w, w_0, X_1D, Y_1D, learning_rate, epochs)\n",
    "\n",
    "print('Final weights:')\n",
    "print(w, w_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "262f6509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8089565304665894\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.1780303])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare result with the sklearn linear regression model.\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_1D = np.array([1, -2, 3, 4.5, 0, -4, -1, 4, -1]).reshape((-1,1))\n",
    "Y_1D = np.array([4,  3, 6, 8  , 2, -3, -2, 7, 2.5])\n",
    "\n",
    "X = np.array([1, -2, 3, 4.5, 0, -4, -1, 4, -1]).reshape(-1,1)\n",
    "reg = LinearRegression().fit(X_1D, Y_1D)\n",
    "print(reg.score(X, y))\n",
    "reg.coef_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "35a520df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.403374017957351"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "y_pred = reg.predict(X_1D)\n",
    "\n",
    "mean_squared_error(Y_1D, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f748fa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "21bce955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape == Y_1D.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
