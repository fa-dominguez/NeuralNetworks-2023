{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac102e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7049610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# Declare a data list\n",
    "data = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
    "\n",
    "# Create a tensor from list\n",
    "tensor_data = torch.tensor(data)\n",
    "\n",
    "print(tensor_data)\n",
    "print(type(tensor_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "525d31b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "# Declare a numpy array\n",
    "np_array = np.array(data)\n",
    "\n",
    "# Create a tensor from numpy\n",
    "tensor_np = torch.tensor(np_array)\n",
    "\n",
    "print(tensor_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec40499",
   "metadata": {},
   "source": [
    "New Tensors can be created from other Tensors. The new one will keep the <b>shape and dataype</b> from the argument, unless explictly override"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d77b077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zeros Tensor: \n",
      " tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.7911, 0.2080, 0.6961],\n",
      "        [0.7797, 0.2187, 0.3251],\n",
      "        [0.6091, 0.0514, 0.1571]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Declare Tensor from tensors\n",
    "\n",
    "# Declare a tensor of 0s with the same shape as tensor_data\n",
    "tensor_zeros = torch.zeros_like(tensor_data)\n",
    "print(f\"Zeros Tensor: \\n {tensor_zeros} \\n\")\n",
    "\n",
    "# Declare a tensor of 1s withe the same shape as tensor_np\n",
    "tensor_ones = torch.ones_like(tensor_np)\n",
    "print(f\"Ones Tensor: \\n {tensor_ones} \\n\")\n",
    "\n",
    "# Declare a random tensor with the the same shape as tensor_np\n",
    "tensor_random = torch.rand_like(tensor_data, dtype = torch.float)\n",
    "print(f\"Random Tensor: \\n {tensor_random} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8aad0334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 3])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of tensor: {tensor_random.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor_random.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor_random.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b96ab99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(2.1764, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Input tensor of ones\n",
    "x = torch.ones(5)\n",
    "# Expected output tensor\n",
    "y = torch.zeros(3)\n",
    "\n",
    "# Weight coefficient\n",
    "w = torch.randn(5, 3, requires_grad = True)\n",
    "\n",
    "# bias coefficient\n",
    "b = torch.rand(3, requires_grad = True)\n",
    "\n",
    "# activation function. Multiplication between x and w + bias.\n",
    "z = torch.matmul(x, w) + b\n",
    "\n",
    "# loss function\n",
    "loss = torch.nn.functional.binary_cross_entropy_with_logits(z,y)\n",
    "\n",
    "print('loss:', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40639ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package torch.nn in torch:\n",
      "\n",
      "NAME\n",
      "    torch.nn\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    _reduction\n",
      "    backends (package)\n",
      "    common_types\n",
      "    cpp\n",
      "    functional\n",
      "    grad\n",
      "    init\n",
      "    intrinsic (package)\n",
      "    modules (package)\n",
      "    parallel (package)\n",
      "    parameter\n",
      "    qat (package)\n",
      "    quantizable (package)\n",
      "    quantized (package)\n",
      "    utils (package)\n",
      "\n",
      "FUNCTIONS\n",
      "    factory_kwargs(kwargs)\n",
      "        Given kwargs, returns a canonicalized dict of factory kwargs that can be directly passed\n",
      "        to factory functions like torch.empty, or errors if unrecognized kwargs are present.\n",
      "        \n",
      "        This function makes it simple to write code like this::\n",
      "        \n",
      "            class MyModule(nn.Module):\n",
      "                def __init__(self, **kwargs):\n",
      "                    factory_kwargs = torch.nn.factory_kwargs(kwargs)\n",
      "                    self.weight = Parameter(torch.empty(10, **factory_kwargs))\n",
      "        \n",
      "        Why should you use this function instead of just passing `kwargs` along directly?\n",
      "        \n",
      "        1. This function does error validation, so if there are unexpected kwargs we will\n",
      "        immediately report an error, instead of deferring it to the factory call\n",
      "        2. This function supports a special `factory_kwargs` argument, which can be used to\n",
      "        explicitly specify a kwarg to be used for factory functions, in the event one of the\n",
      "        factory kwargs conflicts with an already existing argument in the signature (e.g.\n",
      "        in the signature ``def f(dtype, **kwargs)``, you can specify ``dtype`` for factory\n",
      "        functions, as distinct from the dtype argument, by saying\n",
      "        ``f(dtype1, factory_kwargs={\"dtype\": dtype2})``)\n",
      "\n",
      "FILE\n",
      "    /Users/fadominguez/opt/anaconda3/envs/NeuralNetworks/lib/python3.9/site-packages/torch/nn/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98d808a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# Check is mps is working\n",
    "# import torch\n",
    "# if torch.backends.mps.is_available():\n",
    "#     mps_device = torch.device(\"mps\")\n",
    "#     x = torch.ones(1, device=mps_device)\n",
    "#     print (x)\n",
    "# else:\n",
    "#     print (\"MPS device not found.\")\n",
    "\n",
    "# mps turn on the use of GPU on Mac\n",
    "# if torch.backends.mps.is_available():\n",
    "#     tensor = tensor_random.to('mps')\n",
    "#     print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
